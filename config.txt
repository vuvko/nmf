# common params

eps = 1e-7
max_iter = 50
seed = 444
num_threads = 4

# kmeans params

num_clusters = 150
kmeans_max_iter = 50

# anchor params

max_threads = 0
new_dim = 1000

# data params

data_dir = datasets
load_data = uci # 0, no - do not load; 1, csv - csv format; 2, uci - uci format
data_name = nips
gen_name = 0_1_100_16_500

# methods params

# for gradient descent
grad_desc_alpha = 1
grad_desc_alpha_step = 0.8

# for cnmf
cnmf_alpha = 0.1
cnmf_beta = 0.21

# matrix parameters

gen_phi = gen_matrix_topic
gen_theta = gen_matrix_sparse
gen_documents = 1
phi_sparsity = 0.2
theta_sparsity = 0.3

phi_init = gen_matrix_sparse
theta_init = gen_matrix_sparse

N = 100 # number of words
M = 500 # number of documents
T_0 = 15 # "real" number of topics
T = 25 # number of topics

# topic matrix params

nnoise = 1
nkernel = 25
#shift = 5

# experiments params

#experiment = nips_30_T25_conv_p10
experiment = nips_30_T25_plsa_p2
#experiment = test_time
prepare = 0 # -1 --- no preparation
prepare_method = 2
compare_prepare = 0
compare_methods = 0
T_begin = 5
T_end = 100
T_step = 5
run_info = 1 # none(0), results(1), run(2)
runs = 1 # times to run the experiments
schedule = plsa #als,hals,mult,plsa # schedule of methods (no spaces); all methods in methods.py
measure = frobenius,rmse,perplexity # measures to produce; all methods in measure.py
finals = mean_pmi,mean_max_pmi,mean_hell,mean_nhell,min_nhell
compare_real = 0 # compare with real matrices 0, 1
munkres = 1
normalize_iter = 1 # iteration on what to apply normalization
save_results = 0
save_file = results.txt
show_results = 1
result_dir = test/27_05_1/
